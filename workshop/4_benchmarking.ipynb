{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40953bd5-2b0b-4285-a2ba-d5df299f0723",
   "metadata": {},
   "source": [
    "# Benchmarking notebook: CPU vs GPU\n",
    "\n",
    "This notebook run a mini image processing pipeline on the CPU and GPU and compare the average speed.\n",
    "- For CPU processing, we are relying on Scikit-Image library\n",
    "- For GPU processing, we are relying on pyClesperanto library\n",
    "\n",
    "Do not hesitate to update the processing pipeline or play with the different parameters to see their impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee706cfc-7aed-4c9c-931c-c857f5ea05cb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c3e624b-58c5-419f-9eb6-73b859f006d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Scikit-Image (0.24.0) and pyClesperanto (0.13.4)\n"
     ]
    }
   ],
   "source": [
    "import skimage\n",
    "from skimage import io, filters, measure, morphology\n",
    "\n",
    "import pyclesperanto as cle\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "print(f\"Using Scikit-Image ({skimage.__version__}) and pyClesperanto ({cle.__version__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfed29c-e25f-4e79-9479-5410370fc5ad",
   "metadata": {},
   "source": [
    "## GPU initialisation\n",
    "\n",
    "Let's check first what are the different device compatible for GPU-acceleration. We can do this using `cle.info()` that return a descriptions of the devices available.\n",
    "Then we can use `cle.select_device()` to select the most adapted device available. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd415d56-c478-4265-81f3-5b3340754602",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - (OpenCL) NVIDIA GeForce RTX 4090 (OpenCL 3.0 CUDA)\n",
      "\tVendor:                      NVIDIA Corporation\n",
      "\tDriver Version:              535.183.06\n",
      "\tDevice Type:                 GPU\n",
      "\tCompute Units:               128\n",
      "\tGlobal Memory Size:          24183 MB\n",
      "\tMaximum Object Size:         6045 MB\n",
      "\tMax Clock Frequency:         2520 MHz\n",
      "\tImage Support:               Yes\n",
      "1 - (OpenCL) NVIDIA GeForce RTX 4090 (OpenCL 3.0 CUDA)\n",
      "\tVendor:                      NVIDIA Corporation\n",
      "\tDriver Version:              535.183.06\n",
      "\tDevice Type:                 GPU\n",
      "\tCompute Units:               128\n",
      "\tGlobal Memory Size:          24183 MB\n",
      "\tMaximum Object Size:         6045 MB\n",
      "\tMax Clock Frequency:         2520 MHz\n",
      "\tImage Support:               Yes\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cle.info() # return an overview of all available devices for gpu acceleration and their specificities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d7de2dc-817f-4940-aabc-22dea53f166e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(OpenCL) NVIDIA GeForce RTX 4090 (OpenCL 3.0 CUDA)\n",
       "\tVendor:                      NVIDIA Corporation\n",
       "\tDriver Version:              535.183.06\n",
       "\tDevice Type:                 GPU\n",
       "\tCompute Units:               128\n",
       "\tGlobal Memory Size:          24183 MB\n",
       "\tMaximum Object Size:         6045 MB\n",
       "\tMax Clock Frequency:         2520 MHz\n",
       "\tImage Support:               Yes"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cle.select_device(0)  # select device can either take the index of the device, or a sub-string of the device name you want"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beded1a-4a59-4028-8b48-86dce66c2f4f",
   "metadata": {},
   "source": [
    "To finish, we want to set the flag `cle.wait_for_kernel_to_finish()` which will force the GPU to complete its task before giving back the hand to the CPU. \n",
    "This is required when benchmarking in order to have correct time values but not needed when using the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d928a2a4-bbf1-4662-bcf5-eb3b03ecc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle.wait_for_kernel_to_finish(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24116fc2-0565-4077-ab75-4709dfda46d6",
   "metadata": {},
   "source": [
    "## Generate a random data to process\n",
    "\n",
    "Let's generate a random dataset on which to run our pipelines. You can adapte the shape based on your computer capacities. Bigger data size will require more ressources, better highlyting the acceleration provided by the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6a07b5-b038-421e-97f3-bf480f634d88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of the array: 40.00 MB\n"
     ]
    }
   ],
   "source": [
    "shape = (5, 1024, 1024)\n",
    "array = np.random.random(shape) * 100\n",
    "size_in_mb = array.nbytes / (1024 * 1024)\n",
    "print(f\"Size of the array: {size_in_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7bdc2d-d271-4d32-bf73-afcbb283cc8d",
   "metadata": {},
   "source": [
    "## CPU : Scikit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18d2a931-9860-4c3e-a66c-b2a700fde1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: 1.4113 seconds to execute\n",
      "iteration 1: 1.3322 seconds to execute\n",
      "iteration 2: 1.3288 seconds to execute\n",
      "iteration 3: 1.3285 seconds to execute\n",
      "iteration 4: 1.3280 seconds to execute\n",
      "iteration 5: 1.3317 seconds to execute\n",
      "iteration 6: 1.3264 seconds to execute\n",
      "iteration 7: 1.3245 seconds to execute\n",
      "iteration 8: 1.3315 seconds to execute\n",
      "iteration 9: 1.3329 seconds to execute\n",
      "CPU: Average time over 10 iterations: 1.3376 seconds\n"
     ]
    }
   ],
   "source": [
    "# a mini-pipeline running on the CPU using skimage\n",
    "def cpu_pipeline(array, gaussian_sigma=5, tophat_radius=25, opening_radius=3):\n",
    "    if len(array.shape) > 2:\n",
    "        th_kernel = morphology.cube(tophat_radius * 2 + 1)\n",
    "        op_kernel = morphology.cube(opening_radius * 2 + 1)\n",
    "    else:\n",
    "        th_kernel = morphology.square(tophat_radius * 2 + 1)\n",
    "        op_kernel = morphology.square(opening_radius * 2 + 1)\n",
    "        \n",
    "    blurred = filters.gaussian(array, gaussian_sigma)\n",
    "    rm_bg = morphology.white_tophat(blurred, footprint=th_kernel)\n",
    "    binary = blurred > filters.threshold_otsu(rm_bg)\n",
    "    open_binary = morphology.binary_opening(binary, footprint=op_kernel)\n",
    "    label = measure.label(open_binary)\n",
    "    return label\n",
    "\n",
    "# we run the pipeline several time and compute the average processing time\n",
    "iterations = 10\n",
    "times = []\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    cpu_pipeline(array)\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "    print(f\"iteration {i}: {times[-1]:.4f} seconds to execute\")\n",
    "\n",
    "cpu_average_time = sum(times) / iterations\n",
    "print(f\"CPU: Average time over {iterations} iterations: {cpu_average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af05b10-2a78-4a16-85d0-4b3322b1545a",
   "metadata": {},
   "source": [
    "## GPU: pyClesperanot pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "328eb79d-9717-418c-9d49-40609db77166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: 0.3824 seconds to execute\n",
      "iteration 1: 0.0789 seconds to execute\n",
      "iteration 2: 0.0770 seconds to execute\n",
      "iteration 3: 0.0806 seconds to execute\n",
      "iteration 4: 0.0828 seconds to execute\n",
      "iteration 5: 0.0780 seconds to execute\n",
      "iteration 6: 0.0810 seconds to execute\n",
      "iteration 7: 0.0789 seconds to execute\n",
      "iteration 8: 0.0778 seconds to execute\n",
      "iteration 9: 0.0797 seconds to execute\n",
      "GPU: Average time over 10 iterations: 0.1097 seconds\n"
     ]
    }
   ],
   "source": [
    "# a mini-pipeline running on the GPU using pyclesperanto\n",
    "def gpu_pipeline(array, gaussian_sigma=5, tophat_radius=25, opening_radius=3):\n",
    "    blurred = cle.gaussian_blur(array, sigma_x=gaussian_sigma, sigma_y=gaussian_sigma, sigma_z=gaussian_sigma)\n",
    "    rm_bg = cle.top_hat(blurred, radius_x=tophat_radius, radius_y=tophat_radius, radius_z=tophat_radius)\n",
    "    binary = cle.threshold_otsu(rm_bg)\n",
    "    open_binary = cle.opening(binary, radius_x=opening_radius, radius_y=opening_radius, radius_z=opening_radius)\n",
    "    label = cle.connected_component_labeling(open_binary)\n",
    "    return cle.pull(label)\n",
    "\n",
    "# we run the pipeline several time and compute the average processing time\n",
    "iterations = 10\n",
    "times = []\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    gpu_pipeline(array)\n",
    "    end_time = time.time()\n",
    "    times.append(end_time - start_time)\n",
    "    print(f\"iteration {i}: {times[-1]:.4f} seconds to execute\")\n",
    "\n",
    "gpu_average_time = sum(times) / iterations\n",
    "print(f\"GPU: Average time over {iterations} iterations: {gpu_average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1d2aa-f1e8-4fc2-a5e8-32f5ff4b0fe4",
   "metadata": {},
   "source": [
    "## Comparison CPU / GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44939977-69f6-435b-8ff9-1a8ce3690be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speed ratio (CPU time / GPU time): GPU is 12.2 times faster than CPU\n"
     ]
    }
   ],
   "source": [
    "ratio = cpu_average_time / gpu_average_time\n",
    "if ratio > 1:\n",
    "    print(f\"Speed ratio (CPU time / GPU time): GPU is {ratio:.1f} times faster than CPU\")\n",
    "else:\n",
    "    print(f\"Speed ratio (CPU time / GPU time): GPU is {1/ratio:.1f} times slower than CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3401e0-f867-4ca3-ab88-6abb5e75b6d1",
   "metadata": {},
   "source": [
    "Do not hesitate to play with the script and parameter. Data size will, of course, have a strong impact on the processing time, as well as filters parameters like `radius` and `sigma`.\n",
    "\n",
    "Best,  \n",
    "Stephane\n",
    "\n",
    "## Extra:\n",
    "### Who has the fastest GPU in the room?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d3f348-6f5d-4286-a413-715df65eeb27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
