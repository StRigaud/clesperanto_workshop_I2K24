{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40953bd5-2b0b-4285-a2ba-d5df299f0723",
   "metadata": {},
   "source": [
    "# Benchmarking notebook: CPU vs GPU\n",
    "\n",
    "This notebook run a mini image processing pipeline on the CPU and GPU and compare the average speed.\n",
    "- For CPU processing, we are relying on Scikit-Image library\n",
    "- For GPU processing, we are relying on pyClesperanto library\n",
    "\n",
    "Do not hesitate to update the processing pipeline or play with the different parameters to see their impacts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee706cfc-7aed-4c9c-931c-c857f5ea05cb",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c3e624b-58c5-419f-9eb6-73b859f006d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "from skimage import io, filters, measure, morphology\n",
    "\n",
    "import pyclesperanto as cle\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "print(f\"Using Scikit-Image ({skimage.__version__}) and pyclesperanto ({cle.__version__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beded1a-4a59-4028-8b48-86dce66c2f4f",
   "metadata": {},
   "source": [
    "Before doing any benchmarking, we want to set the flag `cle.wait_for_kernel_to_finish()` to `True` which will force the GPU disable the asynchronous processing of the GPU.\n",
    "This is required when benchmarking in order to have correct time values but not usually needed when using the library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d928a2a4-bbf1-4662-bcf5-eb3b03ecc331",
   "metadata": {},
   "outputs": [],
   "source": [
    "cle.wait_for_kernel_to_finish(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24116fc2-0565-4077-ab75-4709dfda46d6",
   "metadata": {},
   "source": [
    "## Generate a random data to process\n",
    "\n",
    "Let's generate a random dataset on which to run our pipelines. You can adapte the shape based on your computer capacities. Bigger data size will require more ressources, better highlyting the acceleration provided by the GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6a07b5-b038-421e-97f3-bf480f634d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape = (5, 1024, 1024) # z, y, x                 You can change the shape here to test different sizes\n",
    "array = np.random.random(shape) * 100\n",
    "size_in_mb = array.nbytes / (1024 * 1024)\n",
    "print(f\"Size of the array: {size_in_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7bdc2d-d271-4d32-bf73-afcbb283cc8d",
   "metadata": {},
   "source": [
    "## CPU : Scikit Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d2a931-9860-4c3e-a66c-b2a700fde1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a mini-pipeline running on the CPU using skimage\n",
    "def cpu_pipeline(array, gaussian_sigma=5, tophat_radius=25, opening_radius=3):\n",
    "    if len(array.shape) > 2:\n",
    "        th_kernel = morphology.cube(tophat_radius * 2 + 1)\n",
    "        op_kernel = morphology.cube(opening_radius * 2 + 1)\n",
    "    else:\n",
    "        th_kernel = morphology.square(tophat_radius * 2 + 1)\n",
    "        op_kernel = morphology.square(opening_radius * 2 + 1)\n",
    "        \n",
    "    blurred = filters.gaussian(array, gaussian_sigma)\n",
    "    rm_bg = morphology.white_tophat(blurred, footprint=th_kernel)\n",
    "    binary = blurred > filters.threshold_otsu(rm_bg)\n",
    "    open_binary = morphology.binary_opening(binary, footprint=op_kernel)\n",
    "    label = measure.label(open_binary)\n",
    "    return label\n",
    "\n",
    "# we run the pipeline several time and compute the average processing time\n",
    "iterations = 10\n",
    "cpu_times = []\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    cpu_pipeline(array)\n",
    "    end_time = time.time()\n",
    "    cpu_times.append(end_time - start_time)\n",
    "    print(f\"iteration {i}: {cpu_times[-1]:.4f} seconds to execute\")\n",
    "\n",
    "cpu_average_time = sum(cpu_times) / iterations\n",
    "print(f\"CPU: Average time over {iterations} iterations: {cpu_average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af05b10-2a78-4a16-85d0-4b3322b1545a",
   "metadata": {},
   "source": [
    "## GPU: pyclesperanto pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "328eb79d-9717-418c-9d49-40609db77166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a mini-pipeline running on the GPU using pyclesperanto\n",
    "def gpu_pipeline(array, gaussian_sigma=5, tophat_radius=25, opening_radius=3):\n",
    "    blurred = cle.gaussian_blur(array, sigma_x=gaussian_sigma, sigma_y=gaussian_sigma, sigma_z=gaussian_sigma)\n",
    "    rm_bg = cle.top_hat(blurred, radius_x=tophat_radius, radius_y=tophat_radius, radius_z=tophat_radius)\n",
    "    binary = cle.threshold_otsu(rm_bg)\n",
    "    open_binary = cle.opening(binary, radius_x=opening_radius, radius_y=opening_radius, radius_z=opening_radius)\n",
    "    label = cle.connected_component_labeling(open_binary)\n",
    "    return cle.pull(label)\n",
    "\n",
    "# we run the pipeline several time and compute the average processing time\n",
    "iterations = 10\n",
    "gpu_times = []\n",
    "for i in range(iterations):\n",
    "    start_time = time.time()\n",
    "    gpu_pipeline(array)\n",
    "    end_time = time.time()\n",
    "    gpu_times.append(end_time - start_time)\n",
    "    print(f\"iteration {i}: {gpu_times[-1]:.4f} seconds to execute\")\n",
    "\n",
    "gpu_average_time = sum(gpu_times) / iterations\n",
    "print(f\"GPU: Average time over {iterations} iterations: {gpu_average_time:.4f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e1d2aa-f1e8-4fc2-a5e8-32f5ff4b0fe4",
   "metadata": {},
   "source": [
    "## Comparison CPU / GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44939977-69f6-435b-8ff9-1a8ce3690be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio = cpu_average_time / gpu_average_time\n",
    "if ratio > 1:\n",
    "    print(f\"Speed ratio ( CPU/GPU time ): GPU is {ratio:.1f} times faster than CPU\")\n",
    "else:\n",
    "    print(f\"Speed ratio ( CPU/GPU time ): GPU is {1/ratio:.1f} times slower than CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea0da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
